{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìö Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üå± NLP spaCy Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.lang.en.English"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚öôÔ∏è Processing a Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\n",
    "    \"\"\"\n",
    "    When Sebastian Thrun started working on self-driving cars at\n",
    "    Google in 2007, few people outside of the company took him\n",
    "    seriously. ‚ÄúI can tell you very senior CEOs of major American\n",
    "    car companies would shake my hand and turn away because I wasn't\n",
    "    worth talking to,‚Äù said Thrun, in an interview with Recode earlier\n",
    "    this week.\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "817"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sebastian Thrun started"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[2:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé´ Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: ['\\n    ', 'When', 'Sebastian', 'Thrun', 'started', 'working', 'on', 'self', '-', 'driving', 'cars', 'at', '\\n    ', 'Google', 'in', '2007', ',', 'few', 'people', 'outside', 'of', 'the', 'company', 'took', 'him', '\\n    ', 'seriously', '.', '‚Äú', 'I', 'can', 'tell', 'you', 'very', 'senior', 'CEOs', 'of', 'major', 'American', '\\n    ', 'car', 'companies', 'would', 'shake', 'my', 'hand', 'and', 'turn', 'away', 'because', 'I', 'was', \"n't\", '\\n    ', 'worth', 'talking', 'to', ',', '‚Äù', 'said', 'Thrun', ',', 'in', 'an', 'interview', 'with', 'Recode', 'earlier', '\\n    ', 'this', 'week', '.', '\\n    ']\n"
     ]
    }
   ],
   "source": [
    "print(\"Text:\", [token.text for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop Words: ['When', 'on', 'at', 'in', 'few', 'of', 'the', 'him', 'I', 'can', 'you', 'very', 'of', 'would', 'my', 'and', 'because', 'I', 'was', \"n't\", 'to', 'in', 'an', 'with', 'this']\n"
     ]
    }
   ],
   "source": [
    "print(\"Stop Words:\", [token.text for token in doc if token.is_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.Defaults.stop_words.add(\"btw\")\n",
    "nlp.vocab[\"btw\"].is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab[\"btw\"].is_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alphanumeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha Numeric:  ['When', 'Sebastian', 'Thrun', 'started', 'working', 'on', 'self', 'driving', 'cars', 'at', 'Google', 'in', 'few', 'people', 'outside', 'of', 'the', 'company', 'took', 'him', 'seriously', 'I', 'can', 'tell', 'you', 'very', 'senior', 'CEOs', 'of', 'major', 'American', 'car', 'companies', 'would', 'shake', 'my', 'hand', 'and', 'turn', 'away', 'because', 'I', 'was', 'worth', 'talking', 'to', 'said', 'Thrun', 'in', 'an', 'interview', 'with', 'Recode', 'earlier', 'this', 'week']\n"
     ]
    }
   ],
   "source": [
    "print(\"Alpha Numeric: \", [token.text for token in doc if token.is_alpha])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capitalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capitalized:  ['When', 'Sebastian', 'Thrun', 'Google', 'I', 'American', 'I', 'Thrun', 'Recode']\n"
     ]
    }
   ],
   "source": [
    "print(\"Capitalized: \", [token.text for token in doc if token.is_title])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ponctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pontuation:  ['-', ',', '.', '‚Äú', ',', '‚Äù', ',', '.']\n"
     ]
    }
   ],
   "source": [
    "print(\"Pontuation: \", [token.text for token in doc if token.is_punct])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical:  ['2007']\n"
     ]
    }
   ],
   "source": [
    "print(\"Numerical: \", [token.text for token in doc if token.like_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences:  ['\\n    ', 'When Sebastian Thrun started working on self-driving cars at\\n    Google in 2007, few people outside of the company took him\\n    seriously.', \"‚ÄúI can tell you very senior CEOs of major American\\n    car companies would shake my hand and turn away because I wasn't\\n    worth talking to,‚Äù said Thrun, in an interview with Recode earlier\\n    this week.\\n    \"]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentences: \", [sent.text for sent in doc.sents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  ['\\n    ', 'Xxxx', 'Xxxxx', 'Xxxxx', 'xxxx', 'xxxx', 'xx', 'xxxx', '-', 'xxxx', 'xxxx', 'xx', '\\n    ', 'Xxxxx', 'xx', 'dddd', ',', 'xxx', 'xxxx', 'xxxx', 'xx', 'xxx', 'xxxx', 'xxxx', 'xxx', '\\n    ', 'xxxx', '.', '‚Äú', 'X', 'xxx', 'xxxx', 'xxx', 'xxxx', 'xxxx', 'XXXx', 'xx', 'xxxx', 'Xxxxx', '\\n    ', 'xxx', 'xxxx', 'xxxx', 'xxxx', 'xx', 'xxxx', 'xxx', 'xxxx', 'xxxx', 'xxxx', 'X', 'xxx', \"x'x\", '\\n    ', 'xxxx', 'xxxx', 'xx', ',', '‚Äù', 'xxxx', 'Xxxxx', ',', 'xx', 'xx', 'xxxx', 'xxxx', 'Xxxxx', 'xxxx', '\\n    ', 'xxxx', 'xxxx', '.', '\\n    ']\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape: \", [token.shape_ for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of Speech (POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS:  ['SPACE', 'SCONJ', 'PROPN', 'PROPN', 'VERB', 'VERB', 'ADP', 'NOUN', 'PUNCT', 'VERB', 'NOUN', 'ADP', 'SPACE', 'PROPN', 'ADP', 'NUM', 'PUNCT', 'ADJ', 'NOUN', 'ADP', 'ADP', 'DET', 'NOUN', 'VERB', 'PRON', 'SPACE', 'ADV', 'PUNCT', 'PUNCT', 'PRON', 'AUX', 'VERB', 'PRON', 'ADV', 'ADJ', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'SPACE', 'NOUN', 'NOUN', 'AUX', 'VERB', 'PRON', 'NOUN', 'CCONJ', 'VERB', 'ADV', 'SCONJ', 'PRON', 'AUX', 'PART', 'SPACE', 'ADJ', 'VERB', 'ADP', 'PUNCT', 'PUNCT', 'VERB', 'PROPN', 'PUNCT', 'ADP', 'DET', 'NOUN', 'ADP', 'PROPN', 'ADV', 'SPACE', 'DET', 'NOUN', 'PUNCT', 'SPACE']\n"
     ]
    }
   ],
   "source": [
    "print(\"POS: \", [token.pos_ for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependency:  ['dep', 'advmod', 'compound', 'nsubj', 'advcl', 'xcomp', 'prep', 'npadvmod', 'punct', 'amod', 'pobj', 'prep', 'dep', 'pobj', 'prep', 'pobj', 'punct', 'amod', 'nsubj', 'advmod', 'prep', 'det', 'pobj', 'ROOT', 'dobj', 'dep', 'advmod', 'punct', 'punct', 'nsubj', 'aux', 'ccomp', 'dative', 'advmod', 'amod', 'nsubj', 'prep', 'amod', 'amod', 'dep', 'compound', 'pobj', 'aux', 'ccomp', 'poss', 'dobj', 'cc', 'conj', 'advmod', 'mark', 'nsubj', 'advcl', 'neg', 'dep', 'acomp', 'xcomp', 'prep', 'punct', 'punct', 'ROOT', 'nsubj', 'punct', 'prep', 'det', 'pobj', 'prep', 'pobj', 'advmod', 'dep', 'det', 'npadvmod', 'punct', 'dep']\n"
     ]
    }
   ],
   "source": [
    "print(\"Dependency: \", [token.dep_ for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma:  ['\\n    ', 'when', 'Sebastian', 'Thrun', 'start', 'work', 'on', 'self', '-', 'drive', 'car', 'at', '\\n    ', 'Google', 'in', '2007', ',', 'few', 'people', 'outside', 'of', 'the', 'company', 'take', 'he', '\\n    ', 'seriously', '.', '\"', 'I', 'can', 'tell', 'you', 'very', 'senior', 'ceo', 'of', 'major', 'american', '\\n    ', 'car', 'company', 'would', 'shake', 'my', 'hand', 'and', 'turn', 'away', 'because', 'I', 'be', \"n't\", '\\n    ', 'worth', 'talk', 'to', ',', '\"', 'say', 'Thrun', ',', 'in', 'an', 'interview', 'with', 'Recode', 'early', '\\n    ', 'this', 'week', '.', '\\n    ']\n"
     ]
    }
   ],
   "source": [
    "print(\"Lemma: \", [token.lemma_ for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morphologic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Morph:  [, , Number=Sing, Number=Sing, Tense=Past|VerbForm=Fin, Aspect=Prog|Tense=Pres|VerbForm=Part, , Number=Sing, PunctType=Dash, Aspect=Prog|Tense=Pres|VerbForm=Part, Number=Plur, , , Number=Sing, , NumType=Card, PunctType=Comm, Degree=Pos, Number=Plur, , , Definite=Def|PronType=Art, Number=Sing, Tense=Past|VerbForm=Fin, Case=Acc|Gender=Masc|Number=Sing|Person=3|PronType=Prs, , , PunctType=Peri, PunctSide=Ini|PunctType=Quot, Case=Nom|Number=Sing|Person=1|PronType=Prs, VerbForm=Fin, VerbForm=Inf, Person=2|PronType=Prs, , Degree=Pos, Number=Plur, , Degree=Pos, Degree=Pos, , Number=Sing, Number=Plur, VerbForm=Fin, VerbForm=Inf, Number=Sing|Person=1|Poss=Yes|PronType=Prs, Number=Sing, ConjType=Cmp, VerbForm=Inf, , , Case=Nom|Number=Sing|Person=1|PronType=Prs, Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin, Polarity=Neg, , Degree=Pos, Aspect=Prog|Tense=Pres|VerbForm=Part, , PunctType=Comm, PunctSide=Fin|PunctType=Quot, Tense=Past|VerbForm=Fin, Number=Sing, PunctType=Comm, , Definite=Ind|PronType=Art, Number=Sing, , Number=Sing, Degree=Cmp, , Number=Sing|PronType=Dem, Number=Sing, PunctType=Peri, ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Morph: \", [token.morph for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üè∑Ô∏è Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity:  [('Sebastian Thrun', 'PERSON'), ('2007', 'DATE'), ('American\\n    ', 'ORG'), ('Thrun', 'GPE'), ('Recode earlier\\n    ', 'ORG'), ('this week', 'DATE')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Entity: \", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚öóÔ∏è Treating Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens with stop words:  {'major', 'talking', 'Sebastian', 'him', 'with', 'company', 'senior', '-', 'to', 'my', 'American', 'turn', 'few', 'an', 'outside', 'earlier', 'this', 'CEOs', 'on', '‚Äù', 'seriously', 'working', ',', \"n't\", 'I', '.', '2007', 'was', 'car', 'said', '\\n    ', 'you', 'self', 'can', 'When', 'hand', 'because', 'worth', 'driving', '‚Äú', 'Recode', 'and', 'very', 'companies', 'interview', 'week', 'away', 'the', 'shake', 'would', 'tell', 'Google', 'at', 'Thrun', 'cars', 'took', 'started', 'in', 'of', 'people'}\n",
      "Tokens without stop words:  {'major', 'talking', 'Sebastian', 'company', 'senior', '-', 'American', 'turn', 'earlier', 'outside', 'CEOs', '‚Äù', 'seriously', 'working', ',', 'I', '.', '2007', 'car', 'said', '\\n    ', 'worth', 'self', 'When', 'hand', 'driving', '‚Äú', 'Recode', 'companies', 'interview', 'week', 'away', 'shake', 'tell', 'Google', 'Thrun', 'cars', 'took', 'started', 'people'}\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(nlp.Defaults.stop_words)\n",
    "doc_tokens = set([token.text for token in doc])\n",
    "\n",
    "tokens_without_sw = doc_tokens - stop_words\n",
    "\n",
    "print(\"Tokens with stop words: \", doc_tokens)\n",
    "print(\"Tokens without stop words: \", tokens_without_sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìñ Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-spacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
